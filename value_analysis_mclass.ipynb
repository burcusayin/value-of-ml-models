{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "value_analysis_mclass_github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeTUOfSQSHPD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This notebook is created to run value analysis with your own model on multi-class datasets\n",
        "#specify the required info here and run the notebook to receive value analysis result for your model\n",
        "modelName = 'name_of_your_model'\n",
        "resPath = 'define_the_path_for_results'\n",
        "data_folder = 'define_the_path_where_you_keep_the_confidence_values_of_your_model_and_the_datasets'\n",
        "confidencesToVal = 'name_of_the_numpy_array_for_the_confidences_on_validation_set.npy'\n",
        "dataToVal = 'name_of_validation_set.csv'\n",
        "confidencesToTest = 'name_of_the_numpy_array_for_the_confidences_on_test_set.npy'\n",
        "dataToTest ='name_of_test_set.csv'\n",
        "ground_truth_column = 'specify_the_column_for_ground_truth_in_your_csv_files'\n",
        "txt = 'specify_the_column_for_text_in_your_csv_files'\n",
        "datasetName = 'name_of_your_dataset'"
      ],
      "metadata": {
        "id": "LRR7zEtDa2y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlHi5AI8SKAx"
      },
      "source": [
        "#result file\n",
        "logfile_name = \"{}_{}\".format(datasetName)\n",
        "\n",
        "#cost-based parameters\n",
        "Vr = 0.0\n",
        "Vc = 1.0\n",
        "Vw_g = list(np.arange(0, -10.1, -1))\n",
        "t_g = list(np.arange(0, 1.01, 0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_val = np.load(data_folder  + confidencesToVal)\n",
        "y_val_df = pd.read_csv(data_folder + dataToVal)\n",
        "y_val = y_val_df[ground_truth_column].values\n",
        "\n",
        "logits_test = np.load(data_folder  + confidencesToTest)\n",
        "y_test_df = pd.read_csv(data_folder + dataToTest)\n",
        "y_test = y_test_df[ground_truth_column].values"
      ],
      "metadata": {
        "id": "IjrUV0I5ZQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK1wDvSfSiwx"
      },
      "source": [
        "def cost_based_threshold(k):\n",
        "    t = (k)/(k+1)\n",
        "    return t\n",
        "\n",
        "def calculate_value(y_hat_proba, y, t, Vr, Vc, Vw):\n",
        "\n",
        "    y_pred = np.array([np.where(l == np.amax(l))[0][0] if (np.amax(l) > t) else -1 for l in y_hat_proba])\n",
        "\n",
        "    # now lets compute the actual value of each prediction\n",
        "    \n",
        "    value_vector = np.full(y_pred.shape[0], Vc)\n",
        "\n",
        "    value_vector[(y_pred != y) & (y_pred != -1)] = Vw\n",
        "    \n",
        "    #loss due to asking humans\n",
        "    value_vector[y_pred == -1] = Vr\n",
        "    value = np.sum(value_vector) / len(y)\n",
        "\n",
        "    numOfRejectedSamples = np.count_nonzero(y_pred == -1)\n",
        "    numOfWrongPredictions = np.count_nonzero((y_pred != y) & (y_pred != -1))\n",
        "    return value, numOfRejectedSamples, numOfWrongPredictions\n",
        "\n",
        "def find_optimum_confidence_threshold(y_hat_proba, y, t_list, Vr, Vc, Vw):\n",
        "\n",
        "    cost_list = {}\n",
        "\n",
        "    for t in t_list:\n",
        "        value, _ , __ = calculate_value(y_hat_proba, y, t, Vr, Vc, Vw)\n",
        "        cost_list[\"{}\".format(t)] = value\n",
        "    # find t values with maximum value\n",
        "    maxValue = max(cost_list.values())\n",
        "    optTList = [float(k) for k, v in cost_list.items() if v == maxValue]\n",
        "    # pick the one with the lowest confidence\n",
        "    optimumT = min(optTList)\n",
        "\n",
        "    return optimumT, cost_list \n",
        "\n",
        "#cost based calibration analysis\n",
        "def cost_based_analysis(y_hat_proba_val, y_val, y_hat_proba_test, y_test, res_path, logfile_name, Vr, Vc, Vw_list, confT_list):\n",
        "\n",
        "    # create log file\n",
        "    rc_path = res_path + logfile_name + \"_costBased_test.csv\"\n",
        "    with open(rc_path, 'w') as f:\n",
        "        c = 'Vr, Vc, Vw, k, t, value, rejected, wrong, t_optimal, value_optimal, rejected_opt, wrong_opt'\n",
        "        f.write(c + '\\n')\n",
        "\n",
        "    for Vw in Vw_list:\n",
        "        k = (-1)*(Vw / Vc)\n",
        "        t = cost_based_threshold(k)\n",
        "        value_test, rej_test, wrong_test = calculate_value(y_hat_proba_test, y_test, t, Vr, Vc, Vw)\n",
        "\n",
        "        t_optimal, cost_list = find_optimum_confidence_threshold(y_hat_proba_val, y_val, confT_list, Vr, Vc, Vw)\n",
        "        value_test_opt, rej_test_opt, wrong_test_opt = calculate_value(y_hat_proba_test, y_test, t_optimal, Vr, Vc, Vw)\n",
        "\n",
        "        with open(rc_path, 'a') as f:\n",
        "            res_i = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\\n'.format(Vr, Vc, Vw, k, t, value_test, rej_test, wrong_test, t_optimal, value_test_opt, rej_test_opt, wrong_test_opt)\n",
        "            f.write(res_i)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1RkiahOSl1v"
      },
      "source": [
        "cost_based_analysis(logits_val, y_val, logits_test, y_test, res_path, logfile_name, Vr, Vc, Vw_g, t_g)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}