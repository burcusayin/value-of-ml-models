{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "value_analysis_tuning_threshold_on_test_set_binary_github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeTUOfSQSHPD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This notebook is created to run value analysis with your own model on binary datasets\n",
        "#Use this code to tune the empirical threshold on test set while running the value analysis\n",
        "#specify the required info here and run the notebook to receive value analysis result for your model\n",
        "modelName = 'name_of_your_model'\n",
        "resPath = 'define_the_path_for_results'\n",
        "data_folder = 'define_the_path_where_you_keep_the_confidence_values_of_your_model_and_the_datasets'\n",
        "confidencesToTest = 'name_of_the_numpy_array_for_the_confidences_on_test_set.npy'\n",
        "dataToTest ='name_of_test_set.csv'\n",
        "ground_truth_column = 'specify_the_column_for_ground_truth_in_your_csv_files'\n",
        "txt = 'specify_the_column_for_text_in_your_csv_files'\n",
        "datasetName = 'name_of_your_dataset'"
      ],
      "metadata": {
        "id": "LRR7zEtDa2y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlHi5AI8SKAx"
      },
      "source": [
        "#result file\n",
        "logfile_name = \"{}_{}_optTest\".format(datasetName)\n",
        "\n",
        "#cost-based parameters\n",
        "Vr = 0.0\n",
        "Vc = 1.0\n",
        "\n",
        "Vw_list_fn = list(np.arange(0, -10.1, -1))\n",
        "Vw_list_fp = list(np.arange(0, -10.1, -1))\n",
        "\n",
        "confT_list = list(np.arange(0, 1.01, 0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_test = np.load(data_folder  + confidencesToTest)\n",
        "y_test_df = pd.read_csv(data_folder + dataToTest)\n",
        "y_test = y_test_df[ground_truth_column].values"
      ],
      "metadata": {
        "id": "IjrUV0I5ZQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK1wDvSfSiwx"
      },
      "source": [
        "def cost_based_threshold(k):\n",
        "    t = (k)/(k+1)\n",
        "    return t\n",
        "\n",
        "def calculate_value(y_hat_proba, y, t_fp, V_fp, t_fn, V_fn, Vc, Vr):\n",
        "    prob_positive = y_hat_proba[:,1]\n",
        "    prob_negative = y_hat_proba[:,0]\n",
        "\n",
        "    y_pred_pos = np.full(prob_positive.shape[0],-1) \n",
        "    y_pred_neg = np.full(prob_negative.shape[0],-1) \n",
        "\n",
        "    y_pred_pos[prob_positive > t_fp] = 1\n",
        "    y_pred_neg[prob_negative > t_fn] = 0\n",
        "\n",
        "    max_prob_indices = list(np.argmax(y_hat_proba, axis=1))\n",
        "\n",
        "    y_pred = np.array([y_pred_neg[i] if max_prob_indices[i] == 0 else y_pred_pos[i] for i in range(len(max_prob_indices))])\n",
        "\n",
        "    # now lets compute the actual value of each prediction\n",
        "    value_vector = np.full(y_pred.shape[0], Vc)\n",
        "\n",
        "    #loss due to false positives and false negatives\n",
        "    false_positives_idx = (y_pred == 1) & ( y == 0)\n",
        "    false_negatives_idx = (y_pred == 0) & ( y == 1)\n",
        "\n",
        "    value_vector[false_positives_idx] = V_fp\n",
        "    value_vector[false_negatives_idx] = V_fn\n",
        "\n",
        "    #loss due to asking humans\n",
        "    value_vector[y_pred == -1] = Vr\n",
        "\n",
        "    value = np.sum(value_vector) / len(y)\n",
        "\n",
        "    numOfRejectedSamples = np.count_nonzero(y_pred == -1)\n",
        "    numOfWrongPredictions = np.count_nonzero((y_pred != y) & (y_pred != -1))\n",
        "    return value, numOfRejectedSamples, numOfWrongPredictions\n",
        "\n",
        "def find_optimum_confidence_threshold(y_hat_proba, y, t_list, Vw_fp, Vw_fn, Vc, Vr):\n",
        "\n",
        "    cost_list = {}\n",
        "\n",
        "    for t_fp in t_list:\n",
        "        for t_fn in t_list:\n",
        "            # here we define K = fn_c_norm, change it based on task. \n",
        "            value = calculate_value(y_hat_proba, y, t_fp, Vw_fp, t_fn, Vw_fn, Vc, Vr)\n",
        "            cost_list[\"{}_{}\".format(t_fp,t_fn)] = value\n",
        "    # find t values with maximum value\n",
        "    maxValue = max(cost_list.values())\n",
        "    optTList = [[float(k.split('_')[0]),float(k.split('_')[1])] for k, v in cost_list.items() if v == maxValue]\n",
        "\n",
        "    return optTList[0], cost_list\n",
        "\n",
        "#cost based calibration analysis\n",
        "def cost_based_analysis(y_hat_proba_test, y_test, res_path, logfile_name, Vr, Vc, Vw_list_fp, Vw_list_fn, confT_list):\n",
        "\n",
        "    # create log file\n",
        "    rc_path = res_path + logfile_name + \"_costBased_test.csv\"\n",
        "    with open(rc_path, 'w') as f:\n",
        "        c = 'Vr, Vc, Vw_fp, Vw_fn, k_fp, k_fn, t_fp, t_fn, value, rejected, wrong, t_optimal_fp, t_optimal_fn, value_optimal, rejected_opt, wrong_opt'\n",
        "        f.write(c + '\\n')\n",
        "\n",
        "    for Vw_fp in Vw_list_fp:\n",
        "        for Vw_fn in Vw_list_fn:\n",
        "            k_fp = (-1)*(Vw_fp / Vc)\n",
        "            k_fn = (-1)*(Vw_fn / Vc)\n",
        "            t_fp = cost_based_threshold(k_fp)\n",
        "            t_fn = cost_based_threshold(k_fn)\n",
        " \n",
        "            value_test, rej_test, wrong_test = calculate_value(y_hat_proba_test, y_test, t_fp, Vw_fp, t_fn, Vw_fn, Vc, Vr)\n",
        "\n",
        "            t_optimal, cost_list = find_optimum_confidence_threshold(y_hat_proba_test, y_test, confT_list, Vw_fp, Vw_fn, Vc, Vr)\n",
        "\n",
        "            value_test_opt, rej_test_opt, wrong_test_opt = calculate_value(y_hat_proba_test, y_test, t_optimal[0], Vw_fp, t_optimal[1], Vw_fn, Vc, Vr)\n",
        "\n",
        "            with open(rc_path, 'a') as f:\n",
        "                res_i = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\\n'.format(Vr, Vc, Vw_fp, Vw_fn, k_fp, k_fn, t_fp, t_fn, value_test, rej_test, wrong_test, t_optimal[0], t_optimal[1], value_test_opt, rej_test_opt, wrong_test_opt)\n",
        "                f.write(res_i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1RkiahOSl1v"
      },
      "source": [
        "cost_based_analysis(logits_test, y_test, resPath, logfile_name, Vr, Vc, Vw_list_fp, Vw_list_fn, confT_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}